{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35d6030c-bd99-410a-9b7f-d8fc4a6a6643",
   "metadata": {},
   "source": [
    "# Solana X Sentiment Analysis for Fraud Detection\r\n",
    "[Messari Logo](Messari.png) X  ![Helius Logo](https://www.helius.dev/logo.svg) X  ![Superteam Logo](https://earn.superteam.fun/assets/logo.svg)\r\n",
    "\r\n",
    "## What This Project Does\r\n",
    "This project checks X (Twitter) sentiment for Solana using Messari's Signal API. It looks for spikes in sentiment, tweet volume, and momentum to spot possible hype or scams. I made this for the Messari Crime Fighting AI Toolkit Hackathon to find suspicious activity on Solana.\r\n",
    "\r\n",
    "It flags a day as suspicious if:\r\n",
    "- Sentiment score is higher than average by a bit (mean + 0.5 standard deviation).\r\n",
    "- Tweet volume jumps by more than 1.2x compared to the previous day.\r\n",
    "- Momentum score is above 0.3 (a big positive change in sentiment).\r\n",
    "\r\n",
    "## What You Need to Run It\r\n",
    "- Python 3.11 or higher\r\n",
    "- Libraries: requests, pandas, numpy\r\n",
    "  Install them by running this in your terminal or \n",
    "  command prompt:command prompt:command prompt:command prompt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e694fbd0-67b0-4f1f-8d74-d1c01f49af67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4fe63060-2d67-4dd2-8219-4bccd4bc24ab",
   "metadata": {},
   "source": [
    "\r\n",
    "## How It works\n",
    "\r\n",
    "1. Get a Messari API key.\r\n",
    "2. In the code, change `API_KEY = \"YOUR_API_KEY\"` to your actual Messari API key.\r\n",
    "3. Run each cell in the notebook by pressing `Shift + Enter`:\r\n",
    " - First cell: Imports the libraries.\r\n",
    " - Second cell: Has the functions to fetch and analyze data.\r\n",
    " - Third cell: Runs the analysis and saves the results.\r\n",
    "\r\n",
    "## What You‚Äôll Get\r\n",
    "- `solana_sentiment_analysis.csv`: A file with the results (dates, sentiment scores, tweet volumes, momentum, and suspicious flags).\r\n",
    "- `twitter_thread.txt`: A ready-to-post Twitter thread summarizing the findings for the hackathon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ed56888f-db36-41ca-8ebb-5b26e268fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b06c451b-b75d-4386-9bdc-66cd1505e42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Messari API key\n",
    "API_KEY = \"YOUR_API_KEY\"\n",
    "\n",
    "# fetch the asset ID for Solana\n",
    "def fetch_solana_asset_id():\n",
    "    url = \"https://api.messari.io/signal/v0/sentiment/assets\"\n",
    "    headers = {\"x-messari-api-key\": API_KEY}\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            assets = response.json()['data']\n",
    "            for asset in assets:\n",
    "                if asset.get('symbol', '').lower() == 'sol' or asset.get('name', '').lower() == 'solana':\n",
    "                    return asset.get('id')\n",
    "            print(\"Solana asset ID not found.\")\n",
    "            return None\n",
    "        else:\n",
    "            print(f\"Error fetching assets: {response.status_code}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# fetch sentiment time-series data for Solana\n",
    "def fetch_solana_sentiment(asset_id):\n",
    "    if not asset_id:\n",
    "        return None\n",
    "    end_date = datetime.utcnow()\n",
    "    start_date = end_date - timedelta(days=7)  # Last 7 days\n",
    "    url = f\"https://api.messari.io/signal/v0/sentiment/assets/{asset_id}/time-series/1d\"\n",
    "    headers = {\"x-messari-api-key\": API_KEY}\n",
    "    params = {\n",
    "        \"start\": start_date.strftime('%Y-%m-%d'),\n",
    "        \"end\": end_date.strftime('%Y-%m-%d'),\n",
    "        \"fields\": \"sentimentScore,tweetVolume\"\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, params=params, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            response_data = response.json()\n",
    "            print(\"Raw API response:\", response_data)\n",
    "            return response_data\n",
    "        else:\n",
    "            print(f\"Error fetching sentiment data: {response.status_code}\")\n",
    "            return None\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Analyze sentiment for spikes\n",
    "def analyze_sentiment_spikes():\n",
    "    # Fetch Solana asset ID\n",
    "    asset_id = fetch_solana_asset_id()\n",
    "    if not asset_id:\n",
    "        return None, None\n",
    "    \n",
    "    # Fetch sentiment data\n",
    "    response_data = fetch_solana_sentiment(asset_id)\n",
    "    if not response_data:\n",
    "        return None, None\n",
    "    \n",
    "    # Extract points and schema\n",
    "    data = response_data.get('data', {})\n",
    "    points = data.get('points', [])\n",
    "    schemas = response_data.get('metadata', {}).get('pointSchemas', [])\n",
    "    \n",
    "    if not points or not schemas:\n",
    "        print(\"No valid sentiment data found in response.\")\n",
    "        return None, None\n",
    "    \n",
    "    # Map schema slugs to indices\n",
    "    schema_mapping = {schema['slug']: idx for idx, schema in enumerate(schemas)}\n",
    "    timestamp_idx = schema_mapping.get('time', 0)\n",
    "    sentiment_score_idx = schema_mapping.get('sentiment-score', 1)\n",
    "    momentum_score_idx = schema_mapping.get('momentum-score', 3)\n",
    "    tweet_volume_idx = schema_mapping.get('tweet-volume', 7)\n",
    "    \n",
    "    # Process data points\n",
    "    results = []\n",
    "    for point in points:\n",
    "        try:\n",
    "            timestamp = int(point[timestamp_idx])\n",
    "            date = datetime.fromtimestamp(timestamp).date()\n",
    "            sentiment_score = float(point[sentiment_score_idx])\n",
    "            momentum_score = float(point[momentum_score_idx])\n",
    "            tweet_volume = int(point[tweet_volume_idx])\n",
    "            results.append({\n",
    "                'date': date,\n",
    "                'sentiment_score': sentiment_score,\n",
    "                'momentum_score': momentum_score,\n",
    "                'tweet_volume': tweet_volume\n",
    "            })\n",
    "        except (IndexError, ValueError, TypeError) as e:\n",
    "            print(f\"Skipping invalid point: {point} (Error: {e})\")\n",
    "            continue\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    if df.empty:\n",
    "        print(\"No valid sentiment data processed.\")\n",
    "        return None, None\n",
    "    \n",
    "    # Flag suspicious days\n",
    "    # Sentiment: > mean + 0.5 std dev\n",
    "    sentiment_mean = df['sentiment_score'].mean()\n",
    "    sentiment_std = df['sentiment_score'].std()\n",
    "    sentiment_threshold = sentiment_mean + 0.5 * sentiment_std\n",
    "    \n",
    "    # Tweet volume: > 1.2x previous day's volume\n",
    "    df['prev_tweet_volume'] = df['tweet_volume'].shift(1).fillna(0)\n",
    "    df['tweet_volume_spike'] = (df['tweet_volume'] > 1.2 * df['prev_tweet_volume']) & (df['prev_tweet_volume'] > 0)\n",
    "    \n",
    "    # Momentum: > 0.3 (significant positive shift)\n",
    "    df['momentum_high'] = df['momentum_score'] > 0.3\n",
    "    \n",
    "    df['suspicious'] = (df['sentiment_score'] > sentiment_threshold) | (df['tweet_volume_spike']) | (df['momentum_high'])\n",
    "    \n",
    "    # Save results\n",
    "    df.to_csv('solana_sentiment_analysis.csv', index=False)\n",
    "    \n",
    "    # Generate summary\n",
    "    suspicious_days = len(df[df['suspicious']])\n",
    "    summary = {\n",
    "        'total_days': len(df),\n",
    "        'suspicious_days': suspicious_days,\n",
    "        'suspicious_percentage': (suspicious_days / len(df) * 100) if len(df) > 0 else 0,\n",
    "        'tweet_volume_trend': 'increasing' if df['tweet_volume'].iloc[-1] > df['tweet_volume'].iloc[0] else 'stable/decreasing'\n",
    "    }\n",
    "    \n",
    "    return df, summary\n",
    "\n",
    "# Generate Twitter thread\n",
    "def generate_twitter_thread(df, summary):\n",
    "    thread = [\n",
    "        \"üîç Investigating potential fraud on Solana via X sentiment using Messari's Signal API! Analyzed sentiment, momentum, and tweet volume to spot spikes that might signal hype or pump-and-dump schemes. #Solana #CryptoFraud #Messari\",\n",
    "        f\"üìä Analyzed {summary['total_days']} days of X sentiment for Solana. Found {summary['suspicious_days']} days ({summary['suspicious_percentage']:.1f}%) with unusual activity (sentiment > avg + 0.5 std dev, tweet volume > 1.2x prev day, or momentum > 0.3).\",\n",
    "        \"‚ö†Ô∏è Suspicious days:\\n\" + \"\\n\".join(\n",
    "            f\"- {row['date']} (Sentiment: {row['sentiment_score']:.1f}, Tweets: {row['tweet_volume']}, Momentum: {row['momentum_score']:.2f})\"\n",
    "            for _, row in df[df['suspicious']].head(3).iterrows()\n",
    "        ) if summary['suspicious_days'] > 0 else \"‚ö†Ô∏è No major spikes, but tweet volume is \" + summary['tweet_volume_trend'] + \"‚Äîwatch for growing hype!\",\n",
    "        \"üí° Why it matters: Sudden X activity spikes can signal coordinated hype. Traders/builders, stay cautious! Code is open-sourced here: [Insert GitHub link] #REDACTEDHackathon @messaricrypto @heliuslabs @SuperteamEarn\",\n",
    "    ]\n",
    "    return thread\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "401f3f83-8b74-457f-afef-b44fa25769ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw API response: {'error': None, 'data': {'points': [[1745020800, 50.69561322063715, 119, -0.35985019141964614, 0.570897, 0.086971, 0.342132, 2955], [1745107200, 50.46397129555794, 109, -0.23164192507920944, 0.569629, 0.088185, 0.342186, 2937], [1745193600, 50.11308214101115, 185, -0.3508891545467918, 0.562222, 0.090556, 0.347222, 3600], [1745280000, 50.481686838583286, 192, 0.3686046975721382, 0.562763, 0.090325, 0.346912, 4517], [1745366400, 50.85769741307628, 208, 0.37601057449299446, 0.565835, 0.0947, 0.339465, 5491], [1745452800, 50.848688657094506, 232, -0.009008755981774641, 0.571561, 0.094898, 0.33354, 6449], [1745539200, 50.6973288263398, 257, -0.15135983075470705, 0.572389, 0.094636, 0.332975, 7439], [1745625600, 49.87047279437642, 167, -0.8268560319633806, 0.570921, 0.095609, 0.33347, 7311]]}, 'metadata': {'pointSchemas': [{'name': 'Timestamp', 'slug': 'time', 'description': 'Timestamp of the data point.', 'isTimestamp': True}, {'name': 'Sentiment Score', 'slug': 'sentiment-score', 'description': 'The sentiment score for the asset. The score ranges from 0 (extremely negative) to 100 (extremely positive).', 'isTimestamp': False}, {'name': 'Sentiment Rank', 'slug': 'sentiment-rank', 'description': 'Sentiment rank of the asset among all assets.', 'isTimestamp': False}, {'name': 'Momentum Score', 'slug': 'momentum-score', 'description': 'The momentum score for the asset.', 'isTimestamp': False}, {'name': 'Positive Post Percent', 'slug': 'positive-post-percent', 'description': 'The percentage of positive sentiment posts for the asset.', 'isTimestamp': False}, {'name': 'Negative Post Percent', 'slug': 'negative-post-percent', 'description': 'The percentage of negative sentiment posts for the asset.', 'isTimestamp': False}, {'name': 'Neutral Post Percent', 'slug': 'neutral-post-percent', 'description': 'The percentage of neutral sentiment posts for the asset.', 'isTimestamp': False}, {'name': 'Tweet Volume', 'slug': 'tweet-volume', 'description': 'The number of tweets for the asset.', 'isTimestamp': False}], 'granularity': '1d'}}\n",
      "Analysis complete! Summary:\n",
      "{\n",
      "  \"total_days\": 8,\n",
      "  \"suspicious_days\": 6,\n",
      "  \"suspicious_percentage\": 75.0,\n",
      "  \"tweet_volume_trend\": \"increasing\"\n",
      "}\n",
      "\n",
      "Sample of results:\n",
      "         date  sentiment_score  tweet_volume  momentum_score  suspicious\n",
      "0  2025-04-19        50.695613          2955       -0.359850        True\n",
      "1  2025-04-20        50.463971          2937       -0.231642       False\n",
      "2  2025-04-21        50.113082          3600       -0.350889        True\n",
      "3  2025-04-22        50.481687          4517        0.368605        True\n",
      "4  2025-04-23        50.857697          5491        0.376011        True\n",
      "\n",
      "Twitter thread saved to twitter_thread.txt\n"
     ]
    }
   ],
   "source": [
    "# Run the analysis\n",
    "if __name__ == \"__main__\":\n",
    "    result = analyze_sentiment_spikes()\n",
    "    if result is None:\n",
    "        print(\"Analysis failed. Check the logs for details.\")\n",
    "    else:\n",
    "        df, summary = result\n",
    "        print(\"Analysis complete! Summary:\")\n",
    "        print(json.dumps(summary, indent=2))\n",
    "        print(\"\\nSample of results:\")\n",
    "        print(df[['date', 'sentiment_score', 'tweet_volume', 'momentum_score', 'suspicious']].head())\n",
    "        \n",
    "        thread = generate_twitter_thread(df, summary)\n",
    "        with open('twitter_thread.txt', 'w', encoding='utf-8') as f:\n",
    "            for i, tweet in enumerate(thread, 1):\n",
    "                f.write(f\"Tweet {i}:\\n{tweet}\\n\\n\")\n",
    "        print(\"\\nTwitter thread saved to twitter_thread.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aba6a4-59ec-4302-a2a9-e285bc933394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
